{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 준비하기 \n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"E:\\데이콘\\\\전복나이 예측\\\\데이터\\\\train.csv\")\n",
    "\n",
    "ques_data = pd.read_csv(\"E:\\데이콘\\\\전복나이 예측\\\\데이터\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Gender', 'Lenght', 'Diameter', 'Height', 'Whole Weight',\n",
      "       'Shucked Weight', 'Viscra Weight', 'Shell Weight', 'Target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viscra 내장\n",
    "Shucked Weight  the weight without the shell\n",
    "Shell Weight 껍질 무게\n",
    "\n",
    "\n",
    "제거할 번호 465, 762, 47, 382, 435, 1078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lenght</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscra Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>466</td>\n",
       "      <td>M</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.125</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id Gender  Lenght  Diameter  Height  Whole Weight  Shucked Weight  \\\n",
       "465  466      M   0.415     0.315   0.125         0.388           0.068   \n",
       "\n",
       "     Viscra Weight  Shell Weight  Target  \n",
       "465           0.09         0.125      12  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Viscra Weight']>train_data['Shucked Weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lenght</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscra Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>I</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>383</td>\n",
       "      <td>I</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>I</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>848</td>\n",
       "      <td>I</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>1079</td>\n",
       "      <td>I</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Gender  Lenght  Diameter  Height  Whole Weight  Shucked Weight  \\\n",
       "47      48      I   0.380     0.275   0.095        0.1375          0.0860   \n",
       "382    383      I   0.455     0.330   0.100        0.3720          0.3580   \n",
       "435    436      I   0.475     0.365   0.100        0.1315          0.2025   \n",
       "847    848      I   0.230     0.165   0.060        0.0515          0.0190   \n",
       "1078  1079      I   0.275     0.205   0.070        0.1055          0.4950   \n",
       "\n",
       "      Viscra Weight  Shell Weight  Target  \n",
       "47           0.0585        0.0605       7  \n",
       "382          0.0775        0.1100       8  \n",
       "435          0.0875        0.1230       7  \n",
       "847          0.0145        0.0360       4  \n",
       "1078         0.0190        0.0315       5  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[(train_data['Shell Weight']+train_data['Shucked Weight'])>train_data['Whole Weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lenght</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscra Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>I</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>1079</td>\n",
       "      <td>I</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Gender  Lenght  Diameter  Height  Whole Weight  Shucked Weight  \\\n",
       "435    436      I   0.475     0.365    0.10        0.1315          0.2025   \n",
       "1078  1079      I   0.275     0.205    0.07        0.1055          0.4950   \n",
       "\n",
       "      Viscra Weight  Shell Weight  Target  \n",
       "435          0.0875        0.1230       7  \n",
       "1078         0.0190        0.0315       5  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Shucked Weight']>train_data['Whole Weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1253, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.drop(index=762,axis =0,inplace= True)\n",
    "train_data.drop(index=465,axis =0,inplace= True)\n",
    "train_data.drop(index=47,axis =0,inplace= True)\n",
    "train_data.drop(index=382,axis =0,inplace= True)\n",
    "train_data.drop(index=435,axis =0,inplace= True)\n",
    "train_data.drop(index=1078,axis =0,inplace= True)\n",
    "#내장무게랑 껍질 무게 헷갈려서 잘못 제거 했었지만 이게 더 효율이 좋길래 유지.\n",
    "#만약 제거 하기 싫으면 이거 지우면댐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1247, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#water = 전체무게 -(껍질무게+껍질을 제외한 무게) 보다 ratio=껍질을 제외한 무게/전체 무게 \n",
    "water_train = train_data['Whole Weight'] -train_data['Shucked Weight']\n",
    "water_ques = ques_data['Whole Weight'] -ques_data['Shucked Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data['Water'] = water_train\n",
    "#ques_data['Water'] = water_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id Gender  Lenght  Diameter  Height  Whole Weight  Shucked Weight  \\\n",
      "0   1      M   0.605     0.470   0.115        1.1140          0.3925   \n",
      "1   2      I   0.430     0.315   0.095        0.3780          0.1750   \n",
      "2   3      I   0.580     0.490   0.195        1.3165          0.5305   \n",
      "3   4      M   0.535     0.405   0.175        1.2705          0.5480   \n",
      "4   5      I   0.310     0.235   0.090        0.1270          0.0480   \n",
      "\n",
      "   Viscra Weight  Shell Weight  Target     Ratio  \n",
      "0         0.2910        0.3100      15  0.352334  \n",
      "1         0.0800        0.1045       8  0.462963  \n",
      "2         0.2540        0.4100      18  0.402962  \n",
      "3         0.3265        0.3370      13  0.431326  \n",
      "4         0.0310        0.0400       6  0.377953  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lenght</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscra Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1.121</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.402765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.297735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.427835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.130</td>\n",
       "      <td>1.102</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.412886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.140</td>\n",
       "      <td>1.113</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.464960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Gender  Lenght  Diameter  Height  Whole Weight  Shucked Weight  \\\n",
       "0   1      F   0.595     0.470   0.155         1.121          0.4515   \n",
       "1   2      M   0.580     0.450   0.150         0.927          0.2760   \n",
       "2   3      I   0.260     0.205   0.070         0.097          0.0415   \n",
       "3   4      M   0.590     0.460   0.130         1.102          0.4550   \n",
       "4   5      F   0.595     0.465   0.140         1.113          0.5175   \n",
       "\n",
       "   Viscra Weight  Shell Weight     Ratio  \n",
       "0         0.1780        0.1550  0.402765  \n",
       "1         0.1815        0.3600  0.297735  \n",
       "2         0.0190        0.0305  0.427835  \n",
       "3         0.2055        0.3300  0.412886  \n",
       "4         0.2440        0.3050  0.464960  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ratio_train =  train_data['Shucked Weight']/train_data['Whole Weight'] \n",
    "Ratio_ques =  ques_data['Shucked Weight']/ques_data['Whole Weight'] \n",
    "train_data['Ratio'] = Ratio_train\n",
    "ques_data['Ratio'] = Ratio_ques\n",
    "print(train_data.head())\n",
    "ques_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1247, 11) (2924, 10) (1247,)\n",
      "(1247, 11) (2924, 11) (1247,)\n"
     ]
    }
   ],
   "source": [
    "train_target = train_data['Target']\n",
    "print(train_data.shape,ques_data.shape,train_target.shape)\n",
    "train_data.drop(['id', 'Target'], axis=1,inplace=True)\n",
    "ques_data.drop(['id'], axis=1,inplace=True)\n",
    "train_data = pd.get_dummies(train_data)\n",
    "ques_data = pd.get_dummies(ques_data)\n",
    "\n",
    "print(train_data.shape,ques_data.shape,train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_input = train_data.to_numpy()\n",
    "train_max_target = train_target.to_numpy()\n",
    "ques_input = ques_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성공학으로도 늘려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_max_input)\n",
    "train_max_scaled = ss.transform(train_max_input)\n",
    "ques_scaled =ss.transform(ques_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_scaled, test_scaled, train_target, test_target = train_test_split(train_max_scaled,train_max_target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1247, 11)\n",
      "(997, 11)\n",
      "(250, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_max_scaled.shape)\n",
    "print(train_scaled.shape)\n",
    "print(test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16)                192       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,473\n",
      "Trainable params: 5,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16,activation='elu', input_dim=11))\n",
    "model.add(keras.layers.Dense(32,activation='elu'))\n",
    "model.add(keras.layers.Dense(64,activation='elu'))\n",
    "model.add(keras.layers.Dropout(0.35))\n",
    "model.add(keras.layers.Dense(32,activation='elu'))\n",
    "model.add(keras.layers.Dense(16,activation='elu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss: 'mean_absolute_error'\n",
    "#optimizer 따로 함수 만들어서 다른것도 만들어보기\n",
    "nadam = keras.optimizers.Nadam(learning_rate=0.0005)\n",
    "model.compile(loss ='mean_absolute_error',optimizer = nadam)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('딥러닝_1(model)', save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=100,restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 1/25 [>.............................] - ETA: 11s - loss: 9.2711INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 8.9550 - val_loss: 7.2532\n",
      "Epoch 2/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 7.6555INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 0s 21ms/step - loss: 6.5409 - val_loss: 4.3487\n",
      "Epoch 3/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 5.3028INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 0s 21ms/step - loss: 4.4841 - val_loss: 3.4169\n",
      "Epoch 4/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 3.6332INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.6438 - val_loss: 2.8464\n",
      "Epoch 5/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 3.7443INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 3.2137 - val_loss: 2.4339\n",
      "Epoch 6/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 2.5613INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.7947 - val_loss: 2.1670\n",
      "Epoch 7/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 2.0749INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.5290 - val_loss: 1.9288\n",
      "Epoch 8/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.8217INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.2543 - val_loss: 1.8461\n",
      "Epoch 9/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.9450INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.0972 - val_loss: 1.6042\n",
      "Epoch 10/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 2.4271INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 2.0248 - val_loss: 1.5021\n",
      "Epoch 11/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.7885INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.9398 - val_loss: 1.4646\n",
      "Epoch 12/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 2.4513INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8274 - val_loss: 1.4540\n",
      "Epoch 13/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.9573INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.7733 - val_loss: 1.4395\n",
      "Epoch 14/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.9182INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.7274 - val_loss: 1.4095\n",
      "Epoch 15/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.7587 - val_loss: 1.4115\n",
      "Epoch 16/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.8862INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.6963 - val_loss: 1.4049\n",
      "Epoch 17/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.6811 - val_loss: 1.4156\n",
      "Epoch 18/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.6757 - val_loss: 1.4836\n",
      "Epoch 19/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 2.2127INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 0s 21ms/step - loss: 1.6632 - val_loss: 1.3967\n",
      "Epoch 20/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.7075INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.6399 - val_loss: 1.3841\n",
      "Epoch 21/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.6279 - val_loss: 1.4296\n",
      "Epoch 22/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.6592 - val_loss: 1.3954\n",
      "Epoch 23/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.6010 - val_loss: 1.3957\n",
      "Epoch 24/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5775 - val_loss: 1.3885\n",
      "Epoch 25/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.6206 - val_loss: 1.4134\n",
      "Epoch 26/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5784 - val_loss: 1.4040\n",
      "Epoch 27/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.4458INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 1.5623 - val_loss: 1.3589\n",
      "Epoch 28/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5607 - val_loss: 1.3658\n",
      "Epoch 29/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5791 - val_loss: 1.4041\n",
      "Epoch 30/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5590 - val_loss: 1.3968\n",
      "Epoch 31/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5929 - val_loss: 1.3819\n",
      "Epoch 32/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5578 - val_loss: 1.3734\n",
      "Epoch 33/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5324 - val_loss: 1.3892\n",
      "Epoch 34/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5747 - val_loss: 1.3681\n",
      "Epoch 35/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5537 - val_loss: 1.4401\n",
      "Epoch 36/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5525 - val_loss: 1.4078\n",
      "Epoch 37/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5584 - val_loss: 1.3843\n",
      "Epoch 38/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5628 - val_loss: 1.3626\n",
      "Epoch 39/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5515 - val_loss: 1.3782\n",
      "Epoch 40/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5561 - val_loss: 1.3589\n",
      "Epoch 41/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.8550INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.5590 - val_loss: 1.3487\n",
      "Epoch 42/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.5351INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.5715 - val_loss: 1.3414\n",
      "Epoch 43/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5033 - val_loss: 1.4067\n",
      "Epoch 44/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5234 - val_loss: 1.3674\n",
      "Epoch 45/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5136 - val_loss: 1.3695\n",
      "Epoch 46/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5409 - val_loss: 1.3956\n",
      "Epoch 47/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5152 - val_loss: 1.3763\n",
      "Epoch 48/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5340 - val_loss: 1.3762\n",
      "Epoch 49/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5010 - val_loss: 1.3599\n",
      "Epoch 50/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5184 - val_loss: 1.3515\n",
      "Epoch 51/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5114 - val_loss: 1.3644\n",
      "Epoch 52/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5421 - val_loss: 1.3889\n",
      "Epoch 53/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5107 - val_loss: 1.3828\n",
      "Epoch 54/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.8199INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.5275 - val_loss: 1.3285\n",
      "Epoch 55/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5036 - val_loss: 1.3755\n",
      "Epoch 56/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5068 - val_loss: 1.3615\n",
      "Epoch 57/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4968 - val_loss: 1.4295\n",
      "Epoch 58/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5038 - val_loss: 1.3684\n",
      "Epoch 59/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5113 - val_loss: 1.3944\n",
      "Epoch 60/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5022 - val_loss: 1.3414\n",
      "Epoch 61/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5153 - val_loss: 1.3487\n",
      "Epoch 62/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5007 - val_loss: 1.3509\n",
      "Epoch 63/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5019 - val_loss: 1.3704\n",
      "Epoch 64/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4817 - val_loss: 1.3562\n",
      "Epoch 65/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5109 - val_loss: 1.3499\n",
      "Epoch 66/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4836 - val_loss: 1.3899\n",
      "Epoch 67/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4888 - val_loss: 1.3506\n",
      "Epoch 68/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.4681INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 1.4908 - val_loss: 1.3159\n",
      "Epoch 69/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4770 - val_loss: 1.3681\n",
      "Epoch 70/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4855 - val_loss: 1.3727\n",
      "Epoch 71/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4876 - val_loss: 1.3661\n",
      "Epoch 72/1000\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.4848 - val_loss: 1.3292\n",
      "Epoch 73/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4844 - val_loss: 1.3255\n",
      "Epoch 74/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4920 - val_loss: 1.3469\n",
      "Epoch 75/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4771 - val_loss: 1.3733\n",
      "Epoch 76/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5002 - val_loss: 1.3826\n",
      "Epoch 77/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5174 - val_loss: 1.3612\n",
      "Epoch 78/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4941 - val_loss: 1.3372\n",
      "Epoch 79/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5014 - val_loss: 1.3356\n",
      "Epoch 80/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4823 - val_loss: 1.3340\n",
      "Epoch 81/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5099 - val_loss: 1.3478\n",
      "Epoch 82/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4557 - val_loss: 1.3315\n",
      "Epoch 83/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4552 - val_loss: 1.3361\n",
      "Epoch 84/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4967 - val_loss: 1.3589\n",
      "Epoch 85/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5064 - val_loss: 1.4588\n",
      "Epoch 86/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4875 - val_loss: 1.3303\n",
      "Epoch 87/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4897 - val_loss: 1.3408\n",
      "Epoch 88/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4847 - val_loss: 1.3441\n",
      "Epoch 89/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4673 - val_loss: 1.3618\n",
      "Epoch 90/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4924 - val_loss: 1.3793\n",
      "Epoch 91/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4736 - val_loss: 1.3250\n",
      "Epoch 92/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4782 - val_loss: 1.3634\n",
      "Epoch 93/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4922 - val_loss: 1.3568\n",
      "Epoch 94/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4767 - val_loss: 1.3370\n",
      "Epoch 95/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.2633INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.4862 - val_loss: 1.3112\n",
      "Epoch 96/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4876 - val_loss: 1.3351\n",
      "Epoch 97/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4907 - val_loss: 1.3183\n",
      "Epoch 98/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4725 - val_loss: 1.3270\n",
      "Epoch 99/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4814 - val_loss: 1.3223\n",
      "Epoch 100/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4788 - val_loss: 1.3438\n",
      "Epoch 101/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4731 - val_loss: 1.3264\n",
      "Epoch 102/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4732 - val_loss: 1.3556\n",
      "Epoch 103/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4867 - val_loss: 1.3479\n",
      "Epoch 104/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4453 - val_loss: 1.3405\n",
      "Epoch 105/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4713 - val_loss: 1.3442\n",
      "Epoch 106/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4682 - val_loss: 1.3199\n",
      "Epoch 107/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4763 - val_loss: 1.3232\n",
      "Epoch 108/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4742 - val_loss: 1.3417\n",
      "Epoch 109/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4688 - val_loss: 1.3491\n",
      "Epoch 110/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4664 - val_loss: 1.3328\n",
      "Epoch 111/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4679 - val_loss: 1.3294\n",
      "Epoch 112/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4555 - val_loss: 1.3257\n",
      "Epoch 113/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4710 - val_loss: 1.3145\n",
      "Epoch 114/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4645 - val_loss: 1.3372\n",
      "Epoch 115/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4600 - val_loss: 1.3414\n",
      "Epoch 116/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4603 - val_loss: 1.3346\n",
      "Epoch 117/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4418 - val_loss: 1.3302\n",
      "Epoch 118/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4727 - val_loss: 1.3273\n",
      "Epoch 119/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4588 - val_loss: 1.3422\n",
      "Epoch 120/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4766 - val_loss: 1.3190\n",
      "Epoch 121/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4976 - val_loss: 1.3473\n",
      "Epoch 122/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4528 - val_loss: 1.3410\n",
      "Epoch 123/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4683 - val_loss: 1.3366\n",
      "Epoch 124/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4664 - val_loss: 1.3255\n",
      "Epoch 125/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4646 - val_loss: 1.3468\n",
      "Epoch 126/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4725 - val_loss: 1.3455\n",
      "Epoch 127/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4611 - val_loss: 1.3488\n",
      "Epoch 128/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4451 - val_loss: 1.3377\n",
      "Epoch 129/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4635 - val_loss: 1.3236\n",
      "Epoch 130/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4575 - val_loss: 1.3539\n",
      "Epoch 131/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4522 - val_loss: 1.3145\n",
      "Epoch 132/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4583 - val_loss: 1.3304\n",
      "Epoch 133/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4511 - val_loss: 1.3470\n",
      "Epoch 134/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4553 - val_loss: 1.3280\n",
      "Epoch 135/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4630 - val_loss: 1.3166\n",
      "Epoch 136/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4569 - val_loss: 1.3217\n",
      "Epoch 137/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4503 - val_loss: 1.3370\n",
      "Epoch 138/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4639 - val_loss: 1.3264\n",
      "Epoch 139/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4524 - val_loss: 1.3244\n",
      "Epoch 140/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4525 - val_loss: 1.4096\n",
      "Epoch 141/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4446 - val_loss: 1.3514\n",
      "Epoch 142/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4698 - val_loss: 1.3445\n",
      "Epoch 143/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4667 - val_loss: 1.3644\n",
      "Epoch 144/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4634 - val_loss: 1.3255\n",
      "Epoch 145/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4460 - val_loss: 1.3246\n",
      "Epoch 146/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4722 - val_loss: 1.3305\n",
      "Epoch 147/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4458 - val_loss: 1.3443\n",
      "Epoch 148/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4483 - val_loss: 1.3521\n",
      "Epoch 149/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4826 - val_loss: 1.3152\n",
      "Epoch 150/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4318 - val_loss: 1.3329\n",
      "Epoch 151/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4567 - val_loss: 1.3189\n",
      "Epoch 152/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4577 - val_loss: 1.3209\n",
      "Epoch 153/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.3146INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 0s 21ms/step - loss: 1.4421 - val_loss: 1.3107\n",
      "Epoch 154/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4459 - val_loss: 1.3194\n",
      "Epoch 155/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.8245INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 1.4449 - val_loss: 1.3031\n",
      "Epoch 156/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4463 - val_loss: 1.3321\n",
      "Epoch 157/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4523 - val_loss: 1.3362\n",
      "Epoch 158/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4623 - val_loss: 1.3314\n",
      "Epoch 159/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4304 - val_loss: 1.3408\n",
      "Epoch 160/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4572 - val_loss: 1.3448\n",
      "Epoch 161/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4546 - val_loss: 1.3301\n",
      "Epoch 162/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4505 - val_loss: 1.3466\n",
      "Epoch 163/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4597 - val_loss: 1.3348\n",
      "Epoch 164/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4339 - val_loss: 1.3095\n",
      "Epoch 165/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4303 - val_loss: 1.3652\n",
      "Epoch 166/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4548 - val_loss: 1.3197\n",
      "Epoch 167/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4428 - val_loss: 1.3206\n",
      "Epoch 168/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4382 - val_loss: 1.3379\n",
      "Epoch 169/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4362 - val_loss: 1.3399\n",
      "Epoch 170/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4623 - val_loss: 1.3452\n",
      "Epoch 171/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4430 - val_loss: 1.3303\n",
      "Epoch 172/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4537 - val_loss: 1.3355\n",
      "Epoch 173/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4379 - val_loss: 1.3578\n",
      "Epoch 174/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4533 - val_loss: 1.3794\n",
      "Epoch 175/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4558 - val_loss: 1.3363\n",
      "Epoch 176/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4605 - val_loss: 1.3189\n",
      "Epoch 177/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4376 - val_loss: 1.3078\n",
      "Epoch 178/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4458 - val_loss: 1.3218\n",
      "Epoch 179/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4414 - val_loss: 1.3524\n",
      "Epoch 180/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4368 - val_loss: 1.3265\n",
      "Epoch 181/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4245 - val_loss: 1.3231\n",
      "Epoch 182/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4523 - val_loss: 1.3212\n",
      "Epoch 183/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4341 - val_loss: 1.3377\n",
      "Epoch 184/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4597 - val_loss: 1.3376\n",
      "Epoch 185/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4391 - val_loss: 1.3270\n",
      "Epoch 186/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4465 - val_loss: 1.3243\n",
      "Epoch 187/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4680 - val_loss: 1.3033\n",
      "Epoch 188/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.3841INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 0s 21ms/step - loss: 1.4374 - val_loss: 1.3026\n",
      "Epoch 189/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4397 - val_loss: 1.3141\n",
      "Epoch 190/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4568 - val_loss: 1.3173\n",
      "Epoch 191/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4241 - val_loss: 1.3183\n",
      "Epoch 192/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4233 - val_loss: 1.3108\n",
      "Epoch 193/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4352 - val_loss: 1.3479\n",
      "Epoch 194/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4483 - val_loss: 1.3138\n",
      "Epoch 195/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4348 - val_loss: 1.3177\n",
      "Epoch 196/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4257 - val_loss: 1.3198\n",
      "Epoch 197/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4290 - val_loss: 1.3201\n",
      "Epoch 198/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4272 - val_loss: 1.3109\n",
      "Epoch 199/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4378 - val_loss: 1.3138\n",
      "Epoch 200/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4456 - val_loss: 1.3428\n",
      "Epoch 201/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4335 - val_loss: 1.3205\n",
      "Epoch 202/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4216 - val_loss: 1.3096\n",
      "Epoch 203/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4442 - val_loss: 1.3242\n",
      "Epoch 204/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4165 - val_loss: 1.3286\n",
      "Epoch 205/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4511 - val_loss: 1.3247\n",
      "Epoch 206/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4450 - val_loss: 1.3306\n",
      "Epoch 207/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4379 - val_loss: 1.3268\n",
      "Epoch 208/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4364 - val_loss: 1.3475\n",
      "Epoch 209/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.5987INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.4461 - val_loss: 1.3026\n",
      "Epoch 210/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1.0682INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.4399 - val_loss: 1.3002\n",
      "Epoch 211/1000\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.9629INFO:tensorflow:Assets written to: 딥러닝_1(model)\\assets\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 1.4201 - val_loss: 1.2946\n",
      "Epoch 212/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4296 - val_loss: 1.3782\n",
      "Epoch 213/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4267 - val_loss: 1.3661\n",
      "Epoch 214/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4413 - val_loss: 1.3273\n",
      "Epoch 215/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4095 - val_loss: 1.3291\n",
      "Epoch 216/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4248 - val_loss: 1.3183\n",
      "Epoch 217/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4143 - val_loss: 1.3274\n",
      "Epoch 218/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4214 - val_loss: 1.3453\n",
      "Epoch 219/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4386 - val_loss: 1.3311\n",
      "Epoch 220/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4263 - val_loss: 1.3319\n",
      "Epoch 221/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4483 - val_loss: 1.3419\n",
      "Epoch 222/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4289 - val_loss: 1.3056\n",
      "Epoch 223/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4434 - val_loss: 1.3344\n",
      "Epoch 224/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4367 - val_loss: 1.3207\n",
      "Epoch 225/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4366 - val_loss: 1.3270\n",
      "Epoch 226/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4110 - val_loss: 1.3182\n",
      "Epoch 227/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4503 - val_loss: 1.3174\n",
      "Epoch 228/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4211 - val_loss: 1.3286\n",
      "Epoch 229/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4303 - val_loss: 1.3687\n",
      "Epoch 230/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4357 - val_loss: 1.3457\n",
      "Epoch 231/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4366 - val_loss: 1.3385\n",
      "Epoch 232/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4076 - val_loss: 1.3222\n",
      "Epoch 233/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4481 - val_loss: 1.3206\n",
      "Epoch 234/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4278 - val_loss: 1.3213\n",
      "Epoch 235/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4316 - val_loss: 1.3511\n",
      "Epoch 236/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4380 - val_loss: 1.3466\n",
      "Epoch 237/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4190 - val_loss: 1.3303\n",
      "Epoch 238/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4117 - val_loss: 1.3449\n",
      "Epoch 239/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4329 - val_loss: 1.3432\n",
      "Epoch 240/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4347 - val_loss: 1.3304\n",
      "Epoch 241/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4609 - val_loss: 1.3209\n",
      "Epoch 242/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4068 - val_loss: 1.3195\n",
      "Epoch 243/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4212 - val_loss: 1.3343\n",
      "Epoch 244/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4345 - val_loss: 1.3336\n",
      "Epoch 245/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4195 - val_loss: 1.3304\n",
      "Epoch 246/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4207 - val_loss: 1.3226\n",
      "Epoch 247/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4208 - val_loss: 1.3373\n",
      "Epoch 248/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4524 - val_loss: 1.3314\n",
      "Epoch 249/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4259 - val_loss: 1.3140\n",
      "Epoch 250/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4208 - val_loss: 1.3149\n",
      "Epoch 251/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4192 - val_loss: 1.3032\n",
      "Epoch 252/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4089 - val_loss: 1.3395\n",
      "Epoch 253/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4153 - val_loss: 1.3173\n",
      "Epoch 254/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4187 - val_loss: 1.3036\n",
      "Epoch 255/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4014 - val_loss: 1.3585\n",
      "Epoch 256/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4312 - val_loss: 1.3130\n",
      "Epoch 257/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4250 - val_loss: 1.3041\n",
      "Epoch 258/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4090 - val_loss: 1.3125\n",
      "Epoch 259/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4167 - val_loss: 1.3423\n",
      "Epoch 260/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4185 - val_loss: 1.3531\n",
      "Epoch 261/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4185 - val_loss: 1.3731\n",
      "Epoch 262/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4420 - val_loss: 1.3361\n",
      "Epoch 263/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4198 - val_loss: 1.3332\n",
      "Epoch 264/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4099 - val_loss: 1.3188\n",
      "Epoch 265/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4231 - val_loss: 1.3189\n",
      "Epoch 266/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4069 - val_loss: 1.3030\n",
      "Epoch 267/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4029 - val_loss: 1.3198\n",
      "Epoch 268/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4276 - val_loss: 1.3329\n",
      "Epoch 269/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4229 - val_loss: 1.3060\n",
      "Epoch 270/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4267 - val_loss: 1.3177\n",
      "Epoch 271/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4105 - val_loss: 1.3087\n",
      "Epoch 272/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4134 - val_loss: 1.3050\n",
      "Epoch 273/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4187 - val_loss: 1.3097\n",
      "Epoch 274/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4235 - val_loss: 1.3143\n",
      "Epoch 275/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4257 - val_loss: 1.3411\n",
      "Epoch 276/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4134 - val_loss: 1.3394\n",
      "Epoch 277/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4131 - val_loss: 1.3188\n",
      "Epoch 278/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4234 - val_loss: 1.3263\n",
      "Epoch 279/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4207 - val_loss: 1.3172\n",
      "Epoch 280/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4417 - val_loss: 1.3449\n",
      "Epoch 281/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4307 - val_loss: 1.3280\n",
      "Epoch 282/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4165 - val_loss: 1.3303\n",
      "Epoch 283/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4078 - val_loss: 1.3318\n",
      "Epoch 284/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4036 - val_loss: 1.3221\n",
      "Epoch 285/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4104 - val_loss: 1.3180\n",
      "Epoch 286/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4126 - val_loss: 1.3134\n",
      "Epoch 287/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4285 - val_loss: 1.3187\n",
      "Epoch 288/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4153 - val_loss: 1.3333\n",
      "Epoch 289/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4117 - val_loss: 1.3543\n",
      "Epoch 290/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.3924 - val_loss: 1.3267\n",
      "Epoch 291/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4057 - val_loss: 1.3116\n",
      "Epoch 292/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4081 - val_loss: 1.3196\n",
      "Epoch 293/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4130 - val_loss: 1.3239\n",
      "Epoch 294/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4158 - val_loss: 1.3399\n",
      "Epoch 295/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4108 - val_loss: 1.3581\n",
      "Epoch 296/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4091 - val_loss: 1.3340\n",
      "Epoch 297/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4177 - val_loss: 1.3188\n",
      "Epoch 298/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4027 - val_loss: 1.3168\n",
      "Epoch 299/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4027 - val_loss: 1.2997\n",
      "Epoch 300/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4253 - val_loss: 1.3330\n",
      "Epoch 301/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4197 - val_loss: 1.3356\n",
      "Epoch 302/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4204 - val_loss: 1.3276\n",
      "Epoch 303/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4251 - val_loss: 1.3254\n",
      "Epoch 304/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4068 - val_loss: 1.3149\n",
      "Epoch 305/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.3899 - val_loss: 1.3076\n",
      "Epoch 306/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4271 - val_loss: 1.3251\n",
      "Epoch 307/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4021 - val_loss: 1.3187\n",
      "Epoch 308/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4117 - val_loss: 1.3109\n",
      "Epoch 309/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4329 - val_loss: 1.3197\n",
      "Epoch 310/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4081 - val_loss: 1.3500\n",
      "Epoch 311/1000\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4165 - val_loss: 1.3441\n",
      "310\n",
      "1.4201310873031616 1.294562816619873\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_scaled,train_target,validation_split=0.2,epochs=1000,callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "print(early_stopping_cb.stopped_epoch)\n",
    "\n",
    "print(history.history['loss'][early_stopping_cb.stopped_epoch-100],history.history['val_loss'][early_stopping_cb.stopped_epoch-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0,3)\n",
    "plt.legend(['train','val'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2924, 1)\n",
      "[[10.038313 ]\n",
      " [15.299606 ]\n",
      " [ 5.3878384]\n",
      " [11.112728 ]\n",
      " [ 9.685949 ]\n",
      " [ 9.895933 ]\n",
      " [ 9.943455 ]\n",
      " [ 7.61701  ]\n",
      " [ 9.845396 ]\n",
      " [ 9.514135 ]]\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(ques_scaled)\n",
    "print(type(ans))\n",
    "print(ans.shape)\n",
    "print(ans[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#submission = pd.read_csv(\"E:\\데이콘\\전복나이 예측\\데이터\\sample_submission.csv\")\n",
    "#submission['Target'] = np.round(ans)\n",
    "#submission.to_csv(\"Submit_16(5).csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0acc62e3991d0f967e612eec664f4e3cdc0de12aaa299698365d7f9a254e36c2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
